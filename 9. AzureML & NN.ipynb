{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комбайны машинного обучения\n",
    "\n",
    "Для автоматизации и формализации построения решения на базе машинного обучения, придумали большие программные комбайны, которые в одном инструменте пройти все необходимые этапы - от сбора данных до развертки итогового решения.\n",
    "\n",
    "Есть платные публичные инструменты, такие как Azureml от Microsoft или SageMaker от AWS, есть внутренние инструменты, например Нирвана в Яндексе, а есть и OpenSource аналоги вроде MLFlow.\n",
    "\n",
    "Сегодня познакомимся с Azureml (поразительно, правда? :) )\n",
    "\n",
    "Весь ноутбук ниже я запускал со своего локального ноутбука на Ubuntu, а не в облаке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала поставим необходимые библиотеки для Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install azureml-train-core azureml-core azureml-automl-runtime matplotlib\n",
    "! wget -O- https://aka.ms/InstallAzureCLIDeb | sudo bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И залогинимся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корневой объект - это Workspace. Это область, где будут производиться все дальнейшие операции.\n",
    "\n",
    "**ВАЖНО** - указывайте свои параметры для subscription_id и resource_group , а не мои :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying KeyVault with name mlworkspkeyvaultd487ae06.\n",
      "Deploying StorageAccount with name mlworkspstoragec2062ce86.\n",
      "Deploying AppInsights with name mlworkspinsights6a635315.\n",
      "Deployed AppInsights with name mlworkspinsights6a635315. Took 8.03 seconds.\n",
      "Deployed KeyVault with name mlworkspkeyvaultd487ae06. Took 25.74 seconds.\n",
      "Deployed StorageAccount with name mlworkspstoragec2062ce86. Took 32.11 seconds.\n",
      "Deploying Workspace with name ml-workspace-1.\n",
      "Deployed Workspace with name ml-workspace-1. Took 33.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(\n",
    "    name = 'ml-workspace-1',\n",
    "    subscription_id = '7d1225ca-27cc-40b7-8036-c62a48072ba8',  # Укажите свою подписку\n",
    "    resource_group = 'lsml-resource-group', # Укажите свою группу\n",
    "    sku = 'enterprise',\n",
    "    exist_ok = True\n",
    ")\n",
    "ws.get_details()\n",
    "\n",
    "ws.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откройте в браузере появившийся ресурс workspace и нажмите \"Запустить студию\". Вам откроется интерфейс студии. В ней можно будет сделать все те же операции, что и мы будем делать через Python. И соответственно отслеживать как идут дела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачу будем решать ту же, что и на предыдущем семинаре - будем учить сетку предсказывать тип одежды из fashion mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p data\n",
    "! wget -O- https://raw.githubusercontent.com/ADKosm/lsml-2021-public/main/data/mnist/fashion-mnist_train.csv.gz | gunzip > data/fashion-mnist_train.csv\n",
    "! wget -O- https://raw.githubusercontent.com/ADKosm/lsml-2021-public/main/data/mnist/fashion-mnist_test.csv.gz | gunzip > data/fashion-mnist_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале загрузим данные в наше облако. Для хранения файлов сущестует Datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading /home/jovyan/data/fashion-mnist_test.csv\n",
      "Uploaded /home/jovyan/data/fashion-mnist_test.csv, 1 files out of an estimated total of 2\n",
      "Uploading /home/jovyan/data/fashion-mnist_train.csv\n",
      "Uploaded /home/jovyan/data/fashion-mnist_train.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_7521b0a4348a416299e0183a6e179c11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_files = [ \n",
    "    os.getcwd() + \"/data/fashion-mnist_train.csv\",\n",
    "    os.getcwd() + \"/data/fashion-mnist_test.csv\"\n",
    "]\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload_files(files=local_files, target_path='fashion-mnist-data', show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По какой-то необъяснимой причине для того, чтобы некоторые функции из Azureml, необходимо поставить .NET на локальный компьютер. Чтож, сделаем это"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb\n",
    "! sudo dpkg -i packages-microsoft-prod.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! apt-get update\n",
    "! apt-get install -y apt-transport-https\n",
    "! apt-get update\n",
    "! apt-get install -y aspnetcore-runtime-2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы данные можно было обрабатывать, их нужно еще собрать в датасеты. Для этого указыаем, из каких файлов в нашем хранилище будет состоять наш датасет и регистрируем его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "dataset = Dataset.File.from_files(path=(datastore, 'fashion-mnist-data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.register(\n",
    "    workspace=ws,\n",
    "    name='fashion-mnist-data',\n",
    "    description='Fashion mnist data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее напишем скрипт обучения. Это обычный скрипт на Python, который как бы запускается из командной строки. Его нужно положить в отдельную директорию. Если для работы скрипта требуются какие-то другие скрипты, то их тоже нужно положить в эту директорию - они все будут доступны из среды выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p torch-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torch-mnist/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torch-mnist/train.py\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from azureml.core.run import Run  # Специальный объект контекста. Он будет использоваться для связью к Azureml\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "def load_data(data_dir, batch_size = 32):\n",
    "    train_csv = pd.read_csv(\"{}/fashion-mnist_train.csv\".format(data_dir))\n",
    "    test_csv = pd.read_csv(\"{}/fashion-mnist_test.csv\".format(data_dir))\n",
    "    \n",
    "    y_train = train_csv['label'].values\n",
    "    X_train = train_csv.drop(['label'],axis=1).values\n",
    "\n",
    "    y_test = test_csv['label'].values\n",
    "    X_test = test_csv.drop(['label'],axis=1).values\n",
    "\n",
    "    torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "    torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "    torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "    torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "    test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def fit(model, train_loader, epoch_number=5, batch_size=32):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoch_number):\n",
    "        correct = 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float().to(device)\n",
    "            var_y_batch = Variable(y_batch).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                loss = loss.data\n",
    "                accuracy = float(correct*100) / float(batch_size*(batch_idx+1))\n",
    "                run.log('Loss', float(loss))  # Вместо обычных print, используем функцию логгирования.\n",
    "                run.log('Accuracy', float(accuracy))  # Эти данные будут собираться и отображаться в студии\n",
    "                \n",
    "                \n",
    "def evaluate(model, test_loader, batch_size=32):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float().to(device)\n",
    "        \n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels.to(device)).sum()\n",
    "    \n",
    "    accuracy = float(correct) / (len(test_loader)*batch_size)\n",
    "    run.log('Test accuracy', accuracy)  # Пишем итоговое качества\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Скрипт будет \"как-бы\" запускаться через командную строку. Поэтому параметры запуска будем получать\n",
    "    # из аргументов командной строки\n",
    "    parser = argparse.ArgumentParser()  \n",
    "    # В следующем параметре указываем директорию, где будут лежать данные для обучения\n",
    "    # Про то, как они туда попадут - ниже\n",
    "    parser.add_argument('--data_path', type=str, help='Path to the training data')\n",
    "    # Директория, куда положить веса модели\n",
    "    parser.add_argument('--output_dir', type=str, help='output directory')\n",
    "    \n",
    "    # Другие параметры модели. Можно добавлять произвольное количество любых параметров\n",
    "    parser.add_argument('--num_epochs', type=int, default=20, help='number of epochs to train')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='number of examples in one batch')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train_loader, test_loader = load_data(args.data_path, batch_size=args.batch_size)\n",
    "    \n",
    "    mlp = MLP()\n",
    "    mlp.to(device)\n",
    "    \n",
    "    fit(mlp, train_loader, epoch_number=args.num_epochs, batch_size=args.batch_size)\n",
    "    evaluate(mlp, test_loader)\n",
    "    \n",
    "    os.makedirs(args.output_dir, exist_ok=True)  # Веса сохраняем в указанную директорию\n",
    "    torch.save(mlp.state_dict(), os.path.join(args.output_dir, 'model.json'))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно необходимо указать, какое окружение для запуска и обучения нам требуется.\n",
    "В специальном файле пропишем пакеты, которые необходимо установитьэ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deps.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile deps.yaml\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - torch==1.6.0\n",
    "  - torchvision==0.7.0\n",
    "  - future==0.17.1\n",
    "  - pillow\n",
    "  - pandas\n",
    "  - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', file_path = './deps.yaml')\n",
    "\n",
    "pytorch_env.docker.enabled = True\n",
    "pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект эксперимента. \n",
    "\n",
    "Эксперимент - это набор запусков, которые призваны решить какую-то одну задачу. Например вы хотите находить котиков на картинке. Тогда создайте эксперимент \"find-cats-on-picture\" и в рамках него попробуйте обучить 10 моделей, которые будут пытаться решить эту задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-fashion'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы что-то где-то считать, нам нужны вычислительные мощности. Поэтому создадим эластичный кластер в нашем рабочем пространстве. Внутри него будем использвать машины с GPU. Там всегда будет минимально 1 машина, но при необхдимости, кластер будет увеличен в размере до 3 машин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating...\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded......................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC6s_v3', # Тип машины с GPU\n",
    "        vm_priority='lowpriority',\n",
    "        min_nodes=1, \n",
    "        max_nodes=3\n",
    "    )\n",
    "\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время запускать обучение. Для этого создаем объект ScriptRunConfig со всеми параметрами.\n",
    "\n",
    "Чтобы подключить к нашему запуску данные, необходимо использовать функцию `as_mount` созданного нами датасета. Если Azureml увидит в аргументах такой объект, то он подключит зарегистрированные данные к определенной директории и передаст путь до этой директории в параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='torch-mnist',\n",
    "    script='train.py',\n",
    "    arguments=[\n",
    "        '--num_epochs', 30, \n",
    "        '--output_dir', './outputs', \n",
    "        '--data_path', dataset.as_named_input('input').as_mount(),\n",
    "        '--batch_size', 32\n",
    "    ],\n",
    "    compute_target=compute_target,\n",
    "    environment=pytorch_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем эксперимент. Перый запуск обычно идет долго. Следить за тем, как там дела у запуска можно из бразера. Можно найти эксперимент в браузере самостоятельно или открыть первую ссылку, которая будет напечана после запуска ячейки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-fashion_1615367971_6d957c76\n",
      "Web View: https://ml.azure.com/experiments/pytorch-fashion/runs/pytorch-fashion_1615367971_6d957c76?wsid=/subscriptions/7d1225ca-27cc-40b7-8036-c62a48072ba8/resourcegroups/lsml-resource-group/workspaces/ml-workspace-1\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2021/03/10 09:19:47 Downloading source code...\n",
      "2021/03/10 09:19:49 Finished downloading source code\n",
      "2021/03/10 09:19:49 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/03/10 09:19:49 Successfully set up Docker network: acb_default_network\n",
      "2021/03/10 09:19:49 Setting up Docker configuration...\n",
      "2021/03/10 09:19:50 Successfully set up Docker configuration\n",
      "2021/03/10 09:19:50 Logging in to registry: 837da93f0d2546bfb509d7917f056196.azurecr.io\n",
      "2021/03/10 09:19:51 Successfully logged into 837da93f0d2546bfb509d7917f056196.azurecr.io\n",
      "2021/03/10 09:19:51 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/03/10 09:19:51 Scanning for dependencies...\n",
      "2021/03/10 09:19:52 Successfully scanned dependencies\n",
      "2021/03/10 09:19:52 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04@sha256:d0ef607847f2d31c5691afd737f437a74267afb8f1e87fef7c9086ed22df4365\n",
      "sha256:d0ef607847f2d31c5691afd737f437a74267afb8f1e87fef7c9086ed22df4365: Pulling from azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\n",
      "d519e2592276: Pulling fs layer\n",
      "d22d2dfcfa9c: Pulling fs layer\n",
      "b3afe92c540b: Pulling fs layer\n",
      "13a10df09dc1: Pulling fs layer\n",
      "4f0bc36a7e1d: Pulling fs layer\n",
      "cd710321007d: Pulling fs layer\n",
      "b42540e9935e: Pulling fs layer\n",
      "f721a7b389f3: Pulling fs layer\n",
      "603d9b7853e1: Pulling fs layer\n",
      "886973c14b5b: Pulling fs layer\n",
      "735c0b52a862: Pulling fs layer\n",
      "b6a79e595b75: Pulling fs layer\n",
      "9aca5289d302: Pulling fs layer\n",
      "60b42f6e844a: Pulling fs layer\n",
      "15e99b1511b7: Pulling fs layer\n",
      "72e30a1c26d4: Pulling fs layer\n",
      "9bae9e45e2f2: Pulling fs layer\n",
      "3d4e69c219a3: Pulling fs layer\n",
      "1e9ce5439ec4: Pulling fs layer\n",
      "13a10df09dc1: Waiting\n",
      "4f0bc36a7e1d: Waiting\n",
      "cd710321007d: Waiting\n",
      "b42540e9935e: Waiting\n",
      "f721a7b389f3: Waiting\n",
      "603d9b7853e1: Waiting\n",
      "886973c14b5b: Waiting\n",
      "735c0b52a862: Waiting\n",
      "b6a79e595b75: Waiting\n",
      "9aca5289d302: Waiting\n",
      "60b42f6e844a: Waiting\n",
      "15e99b1511b7: Waiting\n",
      "72e30a1c26d4: Waiting\n",
      "9bae9e45e2f2: Waiting\n",
      "3d4e69c219a3: Waiting\n",
      "1e9ce5439ec4: Waiting\n",
      "b3afe92c540b: Verifying Checksum\n",
      "b3afe92c540b: Download complete\n",
      "d22d2dfcfa9c: Verifying Checksum\n",
      "d22d2dfcfa9c: Download complete\n",
      "4f0bc36a7e1d: Verifying Checksum\n",
      "4f0bc36a7e1d: Download complete\n",
      "13a10df09dc1: Verifying Checksum\n",
      "13a10df09dc1: Download complete\n",
      "cd710321007d: Verifying Checksum\n",
      "cd710321007d: Download complete\n",
      "f721a7b389f3: Download complete\n",
      "d519e2592276: Verifying Checksum\n",
      "d519e2592276: Download complete\n",
      "886973c14b5b: Verifying Checksum\n",
      "886973c14b5b: Download complete\n",
      "d519e2592276: Pull complete\n",
      "d22d2dfcfa9c: Pull complete\n",
      "b3afe92c540b: Pull complete\n",
      "13a10df09dc1: Pull complete\n",
      "4f0bc36a7e1d: Pull complete\n",
      "cd710321007d: Pull complete\n",
      "b42540e9935e: Verifying Checksum\n",
      "b42540e9935e: Download complete\n",
      "b42540e9935e: Pull complete\n",
      "f721a7b389f3: Pull complete\n",
      "\n",
      "735c0b52a862: Verifying Checksum\n",
      "735c0b52a862: Download complete\n",
      "9aca5289d302: Verifying Checksum\n",
      "9aca5289d302: Download complete\n",
      "60b42f6e844a: Verifying Checksum\n",
      "60b42f6e844a: Download complete\n",
      "603d9b7853e1: Verifying Checksum\n",
      "603d9b7853e1: Download complete\n",
      "72e30a1c26d4: Verifying Checksum\n",
      "72e30a1c26d4: Download complete\n",
      "9bae9e45e2f2: Verifying Checksum\n",
      "9bae9e45e2f2: Download complete\n",
      "3d4e69c219a3: Verifying Checksum\n",
      "3d4e69c219a3: Download complete\n",
      "1e9ce5439ec4: Verifying Checksum\n",
      "1e9ce5439ec4: Download complete\n",
      "15e99b1511b7: Verifying Checksum\n",
      "15e99b1511b7: Download complete\n",
      "\n",
      "603d9b7853e1: Pull complete\n",
      "886973c14b5b: Pull complete\n",
      "735c0b52a862: Pull complete\n",
      "b6a79e595b75: Verifying Checksum\n",
      "b6a79e595b75: Download complete\n",
      "b6a79e595b75: Pull complete\n",
      "9aca5289d302: Pull complete\n",
      "60b42f6e844a: Pull complete\n",
      "15e99b1511b7: Pull complete\n",
      "72e30a1c26d4: Pull complete\n",
      "9bae9e45e2f2: Pull complete\n",
      "3d4e69c219a3: Pull complete\n",
      "1e9ce5439ec4: Pull complete\n",
      "Digest: sha256:d0ef607847f2d31c5691afd737f437a74267afb8f1e87fef7c9086ed22df4365\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04@sha256:d0ef607847f2d31c5691afd737f437a74267afb8f1e87fef7c9086ed22df4365\n",
      " ---> 56f0b19429fe\n",
      "Step 2/18 : USER root\n",
      " ---> Running in 26dd5ea4441b\n",
      "Removing intermediate container 26dd5ea4441b\n",
      " ---> 35ae05ba62da\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 4ed8aff2337b\n",
      "Removing intermediate container 4ed8aff2337b\n",
      " ---> dfa628488f1d\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in 9fbe44caddfe\n",
      "Removing intermediate container 9fbe44caddfe\n",
      " ---> e7e2c69a3ddd\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 06081f91691a\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 1bebb842e7ea\n",
      "Removing intermediate container 1bebb842e7ea\n",
      " ---> 4f7d3445b9cd\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> d9d732000fdd\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 41376c0b5a3a\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "ncurses-5.9          | 1.1 MB    |            |   0% \n",
      "ncurses-5.9          | 1.1 MB    | ########## | 100% \n",
      "ncurses-5.9          | 1.1 MB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 343 KB    |            |   0% \n",
      "xz-5.2.5             | 343 KB    | ########## | 100% \n",
      "xz-5.2.5             | 343 KB    | ########## | 100% \n",
      "\n",
      "python_abi-3.6       | 4 KB      |            |   0% \n",
      "python_abi-3.6       | 4 KB      | ########## | 100% \n",
      "\n",
      "tk-8.5.19            | 1.9 MB    |            |   0% \n",
      "tk-8.5.19            | 1.9 MB    | ########## | 100% \n",
      "tk-8.5.19            | 1.9 MB    | ########## | 100% \n",
      "\n",
      "setuptools-49.6.0    | 936 KB    |            |   0% \n",
      "setuptools-49.6.0    | 936 KB    | 1          |   2% \n",
      "setuptools-49.6.0    | 936 KB    | ########## | 100% \n",
      "setuptools-49.6.0    | 936 KB    | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "certifi-2020.12.5    | 143 KB    |            |   0% \n",
      "certifi-2020.12.5    | 143 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 137 KB    |            |   0% \n",
      "ca-certificates-2020 | 137 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.3.0      | 7.8 MB    |            |   0% \n",
      "libgcc-ng-9.3.0      | 7.8 MB    | ########## | 100% \n",
      "libgcc-ng-9.3.0      | 7.8 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 106 KB    |            |   0% \n",
      "zlib-1.2.11          | 106 KB    | ########## | 100% \n",
      "\n",
      "libgomp-9.3.0        | 376 KB    |            |   0% \n",
      "libgomp-9.3.0        | 376 KB    | ########## | 100% \n",
      "\n",
      "readline-6.2         | 713 KB    |            |   0% \n",
      "readline-6.2         | 713 KB    | ########## | 100% \n",
      "readline-6.2         | 713 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.2 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.2 MB    | ########## | 100% \n",
      "openssl-1.0.2u       | 3.2 MB    | ########## | 100% \n",
      "\n",
      "wheel-0.36.2         | 31 KB     |            |   0% \n",
      "wheel-0.36.2         | 31 KB     | ########## | 100% \n",
      "\n",
      "pip-21.0.1           | 1.1 MB    |            |   0% \n",
      "pip-21.0.1           | 1.1 MB    | ########## | 100% \n",
      "pip-21.0.1           | 1.1 MB    | ########## | 100% \n",
      "\n",
      "sqlite-3.13.0        | 4.9 MB    |            |   0% \n",
      "sqlite-3.13.0        | 4.9 MB    | ########## | 100% \n",
      "sqlite-3.13.0        | 4.9 MB    | ########## | 100% \n",
      "\n",
      "_openmp_mutex-4.5    | 22 KB     |            |   0% \n",
      "_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 19.0 MB   |            |   0% \n",
      "python-3.6.2         | 19.0 MB   | ####5      |  46% \n",
      "python-3.6.2         | 19.0 MB   | ########## | 100% \n",
      "python-3.6.2         | 19.0 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.nkgg5w1x.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.24.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting torch==1.6.0\n",
      "  Downloading torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8 MB)\n",
      "Collecting torchvision==0.7.0\n",
      "  Downloading torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9 MB)\n",
      "Collecting future==0.17.1\n",
      "  Downloading future-0.17.1.tar.gz (829 kB)\n",
      "Collecting pillow\n",
      "  Downloading Pillow-8.1.2-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "Collecting azureml-core~=1.24.0\n",
      "  Downloading azureml_core-1.24.0-py3-none-any.whl (2.2 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.24.0\n",
      "  Downloading azureml_dataset_runtime-1.24.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting six>=1.10\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.6-py2.py3-none-any.whl (55 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting cryptography>=1.1.0\n",
      "  Downloading cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting PyJWT<3,>=1.0.0\n",
      "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.26-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting cryptography>=1.1.0\n",
      "  Downloading cryptography-3.2-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyarrow<2.0.0,>=0.17.0\n",
      "  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting azureml-dataprep<2.12.0a,>=2.11.0a\n",
      "  Downloading azureml_dataprep-2.11.1-py3-none-any.whl (39.4 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-rslex<1.10.0a,>=1.9.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.9.0-cp36-cp36m-manylinux2010_x86_64.whl (8.5 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting azureml-dataprep-native<31.0.0,>=30.0.0\n",
      "  Downloading azureml_dataprep_native-30.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.10.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.12.0-py2.py3-none-any.whl (130 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (32 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.24.0->azureml-defaults->-r /azureml-environment-setup/condaenv.nkgg5w1x.requirements.txt (line 1)) (2020.12.5)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting PyJWT[crypto]<3,>=1.0.0\n",
      "  Downloading PyJWT-2.0.0-py3-none-any.whl (15 kB)\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: future, json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.17.1-py3-none-any.whl size=488729 sha256=cd4b41a289be3bc53b58af50a6a992c59fafa467d5eeaaab686725c2d7134c88\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/f0/e2/8e4ecc9e1b12a428a7657ba683576d3e79d0a75982f63e8fd2\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=28ed53f1533193330063e7e5c9813c96c5b49262897b148bd290c4c290f64b31\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10502 sha256=adcc75230437e9f38b26c00d0039f5a6fb792c4af209eb17ad7e95f86809972a\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=7a9a42162de3841d0a5da1cee10884953361c8cc68a8c36731d3fb1fcd12ae85\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built future json-logging-py fusepy liac-arff\n",
      "Installing collected packages: pycparser, six, cffi, urllib3, PyJWT, idna, cryptography, chardet, requests, portalocker, oauthlib, msal, requests-oauthlib, python-dateutil, msal-extensions, isodate, distro, azure-core, zipp, typing-extensions, numpy, msrest, dotnetcore2, cloudpickle, azureml-dataprep-rslex, azureml-dataprep-native, azure-identity, adal, websocket-client, ruamel.yaml.clib, pytz, pyopenssl, pyasn1, pyarrow, msrestazure, MarkupSafe, jeepney, importlib-metadata, backports.weakref, azureml-dataprep, azure-common, werkzeug, SecretStorage, ruamel.yaml, pathspec, pandas, ndg-httpsclient, liac-arff, jsonpickle, jmespath, Jinja2, itsdangerous, future, fusepy, docker, dill, contextlib2, click, backports.tempfile, azureml-dataset-runtime, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, azure-graphrbac, torch, pillow, json-logging-py, gunicorn, flask, configparser, azureml-model-management-sdk, azureml-core, applicationinsights, torchvision, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.3.1 adal-1.2.6 applicationinsights-0.11.9 azure-common-1.1.26 azure-core-1.12.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.24.0 azureml-dataprep-2.11.1 azureml-dataprep-native-30.0.0 azureml-dataprep-rslex-1.9.0 azureml-dataset-runtime-1.24.0 azureml-defaults-1.24.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.2 dill-0.3.3 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 future-0.17.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-3.7.2 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.10.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.5 oauthlib-3.1.0 pandas-1.1.5 pathspec-0.8.1 pillow-8.1.2 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.16.13 ruamel.yaml.clib-0.2.2 six-1.15.0 torch-1.6.0 torchvision-0.7.0 typing-extensions-3.7.4.3 urllib3-1.26.3 websocket-client-0.58.0 werkzeug-1.0.1 zipp-3.4.1\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing intermediate container 41376c0b5a3a\n",
      " ---> 63c27ef4ff77\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/bin:$PATH\n",
      " ---> Running in 47f8d82c4a29\n",
      "Removing intermediate container 47f8d82c4a29\n",
      " ---> 874da133205b\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> f8b9411bb8e4\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 195bb49db862\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf\n",
      " ---> Running in 86d0802313e6\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 86d0802313e6\n",
      " ---> 621b4904ca78\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf\n",
      " ---> Running in 38186a1ff1f9\n",
      "Removing intermediate container 38186a1ff1f9\n",
      " ---> 7657a274c3f6\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in a41ccd00f989\n",
      "Removing intermediate container a41ccd00f989\n",
      " ---> a325b559d3fd\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 0ea25304e398\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 056d4e507f8b\n",
      "Removing intermediate container 056d4e507f8b\n",
      " ---> d8584eaf7142\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 721e8081759f\n",
      "Removing intermediate container 721e8081759f\n",
      " ---> f5e61bced940\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in 73bc73de437e\n",
      "Removing intermediate container 73bc73de437e\n",
      " ---> 7b31f94094a4\n",
      "Successfully built 7b31f94094a4\n",
      "Successfully tagged 837da93f0d2546bfb509d7917f056196.azurecr.io/azureml/azureml_d20c59ccb9fa8f0211291a59599db59c:latest\n",
      "2021/03/10 09:28:58 Successfully executed container: acb_step_0\n",
      "2021/03/10 09:28:58 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/03/10 09:28:58 Pushing image: 837da93f0d2546bfb509d7917f056196.azurecr.io/azureml/azureml_d20c59ccb9fa8f0211291a59599db59c:latest, attempt 1\n",
      "The push refers to repository [837da93f0d2546bfb509d7917f056196.azurecr.io/azureml/azureml_d20c59ccb9fa8f0211291a59599db59c]\n",
      "b76187872b7c: Preparing\n",
      "c6de713319e4: Preparing\n",
      "5e791eedcf95: Preparing\n",
      "aede0de8f2c3: Preparing\n",
      "2344e33c471c: Preparing\n",
      "21ae344f520c: Preparing\n",
      "cb3e751dc8ac: Preparing\n",
      "1aa1b702d8e3: Preparing\n",
      "002b0fbc07b5: Preparing\n",
      "b5dd59f2de3f: Preparing\n",
      "b2988d0d174e: Preparing\n",
      "7d7984e763b0: Preparing\n",
      "c502e5989d3f: Preparing\n",
      "47725b4cda4f: Preparing\n",
      "17816fecb74d: Preparing\n",
      "ee38f4a8b273: Preparing\n",
      "37bada4196e0: Preparing\n",
      "5c988c69d95b: Preparing\n",
      "cb564eb69095: Preparing\n",
      "293fc2877886: Preparing\n",
      "e7b2621d69c1: Preparing\n",
      "2bea4d74b96a: Preparing\n",
      "22e5301e2e28: Preparing\n",
      "39f2ac3f3a16: Preparing\n",
      "18ca1325d756: Preparing\n",
      "9f10818f1f96: Preparing\n",
      "27502392e386: Preparing\n",
      "c95d2191d777: Preparing\n",
      "21ae344f520c: Waiting\n",
      "cb3e751dc8ac: Waiting\n",
      "1aa1b702d8e3: Waiting\n",
      "002b0fbc07b5: Waiting\n",
      "b5dd59f2de3f: Waiting\n",
      "b2988d0d174e: Waiting\n",
      "7d7984e763b0: Waiting\n",
      "c502e5989d3f: Waiting\n",
      "47725b4cda4f: Waiting\n",
      "17816fecb74d: Waiting\n",
      "ee38f4a8b273: Waiting\n",
      "37bada4196e0: Waiting\n",
      "5c988c69d95b: Waiting\n",
      "cb564eb69095: Waiting\n",
      "293fc2877886: Waiting\n",
      "e7b2621d69c1: Waiting\n",
      "2bea4d74b96a: Waiting\n",
      "22e5301e2e28: Waiting\n",
      "39f2ac3f3a16: Waiting\n",
      "18ca1325d756: Waiting\n",
      "9f10818f1f96: Waiting\n",
      "27502392e386: Waiting\n",
      "c95d2191d777: Waiting\n",
      "aede0de8f2c3: Pushed\n",
      "5e791eedcf95: Pushed\n",
      "b76187872b7c: Pushed\n",
      "c6de713319e4: Pushed\n",
      "21ae344f520c: Pushed\n",
      "1aa1b702d8e3: Pushed\n",
      "cb3e751dc8ac: Pushed\n",
      "002b0fbc07b5: Pushed\n",
      "b5dd59f2de3f: Pushed\n",
      "b2988d0d174e: Pushed\n",
      "7d7984e763b0: Pushed\n",
      "c502e5989d3f: Pushed\n",
      "17816fecb74d: Pushed\n",
      "ee38f4a8b273: Pushed\n",
      "cb564eb69095: Pushed\n",
      "47725b4cda4f: Pushed\n",
      "e7b2621d69c1: Pushed\n",
      "5c988c69d95b: Pushed\n",
      "22e5301e2e28: Pushed\n",
      "39f2ac3f3a16: Pushed\n",
      "18ca1325d756: Pushed\n",
      "9f10818f1f96: Pushed\n",
      "27502392e386: Pushed\n",
      "c95d2191d777: Pushed\n",
      "2bea4d74b96a: Pushed\n",
      "293fc2877886: Pushed\n",
      "2344e33c471c: Pushed\n",
      "37bada4196e0: Pushed\n",
      "latest: digest: sha256:bb0a05fc78c314d28f908f7a1d8ebd20616893f29a0b3f7b5c32532e810e48eb size: 6200\n",
      "2021/03/10 09:36:32 Successfully pushed image: 837da93f0d2546bfb509d7917f056196.azurecr.io/azureml/azureml_d20c59ccb9fa8f0211291a59599db59c:latest\n",
      "2021/03/10 09:36:32 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 547.318714)\n",
      "2021/03/10 09:36:32 Populating digests for step ID: acb_step_0...\n",
      "2021/03/10 09:36:34 Successfully populated digests for step ID: acb_step_0\n",
      "2021/03/10 09:36:34 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 453.553449)\n",
      "2021/03/10 09:36:34 The following dependencies were found:\n",
      "2021/03/10 09:36:34 \n",
      "- image:\n",
      "    registry: 837da93f0d2546bfb509d7917f056196.azurecr.io\n",
      "    repository: azureml/azureml_d20c59ccb9fa8f0211291a59599db59c\n",
      "    tag: latest\n",
      "    digest: sha256:bb0a05fc78c314d28f908f7a1d8ebd20616893f29a0b3f7b5c32532e810e48eb\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\n",
      "    digest: sha256:d0ef607847f2d31c5691afd737f437a74267afb8f1e87fef7c9086ed22df4365\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cf2 was successful after 16m47s\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021/03/10 09:38:07 Attempt 1 of http call to http://10.0.0.7:16384/sendlogstoartifacts/info\n",
      "bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021/03/10 09:38:07 Attempt 1 of http call to http://10.0.0.7:16384/sendlogstoartifacts/status\n",
      "[2021-03-10T09:38:08.976378] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--num_epochs', '30', '--output_dir', './outputs', '--data_path', 'DatasetConsumptionConfig:input', '--batch_size', '32'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 83\n",
      "[2021-03-10T09:38:10.843384] Entering Run History Context Manager.\n",
      "[2021-03-10T09:38:11.553218] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615367971_6d957c76/mounts/workspaceblobstore/azureml/pytorch-fashion_1615367971_6d957c76\n",
      "[2021-03-10T09:38:11.553361] Preparing to call script [train.py] with arguments:['--num_epochs', '30', '--output_dir', './outputs', '--data_path', '$input', '--batch_size', '32']\n",
      "[2021-03-10T09:38:11.553436] After variable expansion, calling script [train.py] with arguments:['--num_epochs', '30', '--output_dir', './outputs', '--data_path', '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615367971_6d957c76/wd/tmpf44se5x6', '--batch_size', '32']\n",
      "\n",
      "2021/03/10 09:38:12 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-03-10T09:40:43.174029] Entering job release\n",
      "[2021-03-10T09:40:44.423088] Starting job release\n",
      "[2021-03-10T09:40:44.423578] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 377\n",
      "[2021-03-10T09:40:44.424206] job release stage : upload_datastore starting...\n",
      "[2021-03-10T09:40:44.424487] job release stage : start importing azureml.history._tracking in run_history_release.[2021-03-10T09:40:44.424682] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "[2021-03-10T09:40:44.432781] job release stage : execute_job_release starting...[2021-03-10T09:40:44.432825] job release stage : copy_batchai_cached_logs completed...\n",
      "\n",
      "[2021-03-10T09:40:44.475901] Entering context manager injector.\n",
      "[2021-03-10T09:40:44.517720] job release stage : upload_datastore completed...\n",
      "[2021-03-10T09:40:44.630711] job release stage : send_run_telemetry starting...\n",
      "[2021-03-10T09:40:44.806331] job release stage : execute_job_release completed...\n",
      "[2021-03-10T09:40:44.810897] get vm size and vm region successfully.\n",
      "[2021-03-10T09:40:44.824505] get compute meta data successfully.\n",
      "[2021-03-10T09:40:45.028470] post artifact meta request successfully.\n",
      "[2021-03-10T09:40:45.062048] upload compute record artifact successfully.\n",
      "[2021-03-10T09:40:45.228595] job release stage : send_run_telemetry completed...\n",
      "[2021-03-10T09:40:45.228792] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-03-10T09:40:45.228908] Running Sidecar release cmd...\n",
      "[2021-03-10T09:40:45.239123] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615367971_6d957c76/mounts/workspaceblobstore/azureml/pytorch-fashion_1615367971_6d957c76\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615367971_6d957c76/wd/tmpf44se5x6.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615367971_6d957c76/wd/tmpf44se5x6.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-03-10T09:40:45.406535] Removing absolute paths from host...\n",
      "[2021-03-10T09:40:45.546324] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-03-10T09:40:46.309448] Ran Sidecar release cmd.\n",
      "[2021-03-10T09:40:46.309483] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-fashion_1615367971_6d957c76\n",
      "Web View: https://ml.azure.com/experiments/pytorch-fashion/runs/pytorch-fashion_1615367971_6d957c76?wsid=/subscriptions/7d1225ca-27cc-40b7-8036-c62a48072ba8/resourcegroups/lsml-resource-group/workspaces/ml-workspace-1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'pytorch-fashion_1615367971_6d957c76',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-03-10T09:37:06.874265Z',\n",
       " 'endTimeUtc': '2021-03-10T09:40:55.874578Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'c29bf0aa-4e8e-4a64-a345-d9e1c384f763',\n",
       "  'azureml.git.repository_uri': 'git@github.com:ADKosm/lsml-2021-internal.git',\n",
       "  'mlflow.source.git.repoURL': 'git@github.com:ADKosm/lsml-2021-internal.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '4930b05f6a80ba0707e4a0c958d4c990c07254ac',\n",
       "  'mlflow.source.git.commit': '4930b05f6a80ba0707e4a0c958d4c990c07254ac',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'c5ccb8c4-acfd-4995-b18a-7796cf9e5753'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--num_epochs',\n",
       "   '30',\n",
       "   '--output_dir',\n",
       "   './outputs',\n",
       "   '--data_path',\n",
       "   'DatasetConsumptionConfig:input',\n",
       "   '--batch_size',\n",
       "   '32'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'gpucluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input': {'dataLocation': {'dataset': {'id': 'c5ccb8c4-acfd-4995-b18a-7796cf9e5753',\n",
       "      'name': 'fashion-mnist-data',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'pytorch-1.6-gpu',\n",
       "   'version': 'Autosave_2021-03-10T09:19:36Z_1db1c859',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'torch==1.6.0',\n",
       "        'torchvision==0.7.0',\n",
       "        'future==0.17.1',\n",
       "        'pillow',\n",
       "        'pandas',\n",
       "        'numpy']}],\n",
       "     'name': 'azureml_b12a18c42a13060a35e6f25ecbe6a0bf'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=sp02TwfSg6RfEBjc9Hkw0DuHUxgYvKo%2BycGLckt%2BPQQ%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/55_azureml-execution-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt?sv=2019-02-02&sr=b&sig=FmMB%2FljTHuqlFE7P%2Fx7%2Bppe7k7htr1ObqQog2qcEDq0%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/65_job_prep-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt?sv=2019-02-02&sr=b&sig=jDZCoFbrZR1hlSrD5C6oUqgRfZFPbLACVP3zRf7R22E%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=PVqoEsrngtkGjSNtBh42Np4txXbvkzHncZivuamWH18%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/75_job_post-tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p.txt?sv=2019-02-02&sr=b&sig=%2BKH6TGlY%2FrLMYVqZNQLz8H4QlJ9nQ2%2FJiD0js7SNPro%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=15V9EXsTzyft4mXJ2xS2bpYOT6SsSSVsB2YlsWruqGg%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=QcW2PNGYPV9YXJRlfIuIAffB%2F0HR8kDKNwGqxV3UELA%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/83_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/83_azureml.log?sv=2019-02-02&sr=b&sig=IcUljDr5e4mNNdF6DjCZ0u8FV21OtJdQFYgDieW3nkg%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=NwFYiDlEN03Q2o%2FFrsZq86%2FR3oB3N%2FDWD5BmdQhEJMk%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=CSmzUTVzZRME621GsngnUB7nSMkZGlFPM7dxfMzSqiE%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=yVhmoAljdYIJnzstxBme%2F2Q0ApfbtX02NBzrW9NuIBQ%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=YquGVp6qgIqnCQl1SsSJxEoWhitAcw4e5MWsIMmV8ek%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p/all.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/sidecar/tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p/all.log?sv=2019-02-02&sr=b&sig=36WKAuDGhxxQJbsDUFCmfO0JYJNcPWwjNrWsBoeyikc%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p/task.enter_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/sidecar/tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=IWbrGTQHUf8Za%2FWDJ59DG32gIHT76Au622Ja3yURUpI%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p/task.exit_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615367971_6d957c76/logs/azureml/sidecar/tvmps_ffc1705c49b22457724c845fab4b304d49b1e92f1986adf0b4fc36c112c3d45e_p/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=syezLcrtqRvuTEter2WKIPtPSldJ9DBauD4hpAT1GAY%3D&st=2021-03-10T09%3A31%3A19Z&se=2021-03-10T17%3A41%3A19Z&sp=r'},\n",
       " 'submittedBy': 'Алексей Космачев'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(src)\n",
    "run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После успешного запуска полученную модель можно сохранить. Для этого используем метод `register_model`, где указываем, в какую директорию мы сохранили веса нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='mnist-fashion-torch-mlp', model_path='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='ml-workspace-1', subscription_id='7d1225ca-27cc-40b7-8036-c62a48072ba8', resource_group='lsml-resource-group'), name=mnist-fashion-torch-mlp, id=mnist-fashion-torch-mlp:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий важный шаг - развернуть полученную модель в облаке, чтобы можно было сделать запрос по HTTP и получить предсказание.\n",
    "\n",
    "Для этого необходимо реализовать питон-скрипт, в котором будут две функции\n",
    "\n",
    "* `init` - она будет запущена 1 раз при инициализации. В ней нужно подготовить модеть к запуску\n",
    "* `run` - она принимает тело запроса, которое пришло на эндпоинт и должно вернуть предсказание по этим данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting torch-mnist/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile torch-mnist/score.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import json\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    model = MLP()\n",
    "    \n",
    "    model_root = Model.get_model_path('mnist-fashion-torch-mlp')  # Через инструмент Model понимаем, где веса модели\n",
    "    model_path = os.path.join(model_root, 'model.json')\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))  # Загружаем веса\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    # В input_data - данные, которые прилетели от пользователя\n",
    "    input_data = Variable(torch.from_numpy(np.array(json.loads(input_data)['data'])).type(torch.LongTensor).float())\n",
    "\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    out = model(input_data)\n",
    "    pred_probs = softmax(out)\n",
    "    index = torch.argmax(pred_probs[0]).item()\n",
    "    \n",
    "    return {'label': index, \"probability\": pred_probs[0][index].item()}  # Возвращаем предсказание (формат может быть любым)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указываем, где лежит этот скрипт, какое ему нужно окружение, какие мощности нужны для работы модели и запускает процесс развертки. Он тоже не слишком быстрый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running..........................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"torch-mnist/score.py\", environment=pytorch_env)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(\n",
    "    cpu_cores=1, \n",
    "    memory_gb=1, \n",
    "    tags={'data': 'fashion-mnist', 'framework':'pytorch'},\n",
    "    description='Classify clothes'\n",
    ")\n",
    "\n",
    "service = Model.deploy(\n",
    "    workspace=ws, \n",
    "    name='fashin-mnist-torch-inf',\n",
    "    models=[model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=aciconfig\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-03-10T09:58:20,636215200+00:00 - rsyslog/run \n",
      "2021-03-10T09:58:20,655107300+00:00 - iot-server/run \n",
      "2021-03-10T09:58:20,661433200+00:00 - gunicorn/run \n",
      "bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021-03-10T09:58:20,724263600+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_b12a18c42a13060a35e6f25ecbe6a0bf/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-03-10T09:58:22,741243000+00:00 - iot-server/finish 1 0\n",
      "2021-03-10T09:58:22,744377100+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (72)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 102\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-03-10 09:58:33,483 | root | INFO | Starting up app insights client\n",
      "2021-03-10 09:58:33,483 | root | INFO | Starting up request id generator\n",
      "2021-03-10 09:58:33,484 | root | INFO | Starting up app insight hooks\n",
      "2021-03-10 09:58:33,484 | root | INFO | Invoking user's init function\n",
      "2021-03-10 09:58:33,604 | root | INFO | Users's init has completed successfully\n",
      "2021-03-10 09:58:33,621 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-03-10 09:58:33,621 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-03-10 09:58:33,622 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-03-10 09:58:35,239 | root | INFO | Swagger file not present\n",
      "2021-03-10 09:58:35,239 | root | INFO | 404\n",
      "127.0.0.1 - - [10/Mar/2021:09:58:35 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-03-10 09:58:39,646 | root | INFO | Swagger file not present\n",
      "2021-03-10 09:58:39,647 | root | INFO | 404\n",
      "127.0.0.1 - - [10/Mar/2021:09:58:39 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу получаем специальный URL, на который можно слать HTTP запросы и получать ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://133d198e-aaa7-4fc9-a206-3d25af84b44e.westus.azurecontainer.io/score'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные локально и сделаем такой запрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df.drop(['label'],axis=1).values\n",
    "y_test = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26b00ee070>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26abfa3bb0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26abf0c370>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"label\": 2, \"probability\": 0.9100812077522278}'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r_data = [X_test[2].tolist()]\n",
    "\n",
    "r = requests.post(service.scoring_uri, json={\n",
    "    'method': 'predict',\n",
    "    'data': r_data\n",
    "})\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 34,\n",
       " 29,\n",
       " 7,\n",
       " 0,\n",
       " 11,\n",
       " 24,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 44,\n",
       " 88,\n",
       " 99,\n",
       " 122,\n",
       " 123,\n",
       " 80,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 46,\n",
       " 174,\n",
       " 249,\n",
       " 67,\n",
       " 0,\n",
       " 94,\n",
       " 210,\n",
       " 61,\n",
       " 14,\n",
       " 212,\n",
       " 157,\n",
       " 37,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 23,\n",
       " 168,\n",
       " 206,\n",
       " 242,\n",
       " 239,\n",
       " 238,\n",
       " 214,\n",
       " 125,\n",
       " 61,\n",
       " 113,\n",
       " 74,\n",
       " 133,\n",
       " 236,\n",
       " 238,\n",
       " 236,\n",
       " 203,\n",
       " 184,\n",
       " 20,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 175,\n",
       " 245,\n",
       " 223,\n",
       " 207,\n",
       " 205,\n",
       " 206,\n",
       " 216,\n",
       " 255,\n",
       " 237,\n",
       " 251,\n",
       " 232,\n",
       " 223,\n",
       " 212,\n",
       " 200,\n",
       " 205,\n",
       " 216,\n",
       " 249,\n",
       " 173,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 53,\n",
       " 225,\n",
       " 201,\n",
       " 197,\n",
       " 200,\n",
       " 201,\n",
       " 206,\n",
       " 199,\n",
       " 197,\n",
       " 185,\n",
       " 194,\n",
       " 204,\n",
       " 232,\n",
       " 226,\n",
       " 249,\n",
       " 219,\n",
       " 194,\n",
       " 205,\n",
       " 229,\n",
       " 33,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 133,\n",
       " 223,\n",
       " 208,\n",
       " 192,\n",
       " 195,\n",
       " 233,\n",
       " 226,\n",
       " 216,\n",
       " 191,\n",
       " 210,\n",
       " 188,\n",
       " 236,\n",
       " 186,\n",
       " 0,\n",
       " 50,\n",
       " 234,\n",
       " 207,\n",
       " 208,\n",
       " 231,\n",
       " 133,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 216,\n",
       " 218,\n",
       " 216,\n",
       " 194,\n",
       " 229,\n",
       " 172,\n",
       " 64,\n",
       " 219,\n",
       " 201,\n",
       " 200,\n",
       " 200,\n",
       " 247,\n",
       " 68,\n",
       " 72,\n",
       " 54,\n",
       " 165,\n",
       " 237,\n",
       " 212,\n",
       " 219,\n",
       " 226,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 50,\n",
       " 221,\n",
       " 207,\n",
       " 220,\n",
       " 211,\n",
       " 207,\n",
       " 165,\n",
       " 138,\n",
       " 205,\n",
       " 192,\n",
       " 191,\n",
       " 190,\n",
       " 232,\n",
       " 119,\n",
       " 113,\n",
       " 67,\n",
       " 173,\n",
       " 237,\n",
       " 217,\n",
       " 208,\n",
       " 221,\n",
       " 29,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 131,\n",
       " 216,\n",
       " 200,\n",
       " 219,\n",
       " 207,\n",
       " 212,\n",
       " 231,\n",
       " 226,\n",
       " 193,\n",
       " 214,\n",
       " 224,\n",
       " 206,\n",
       " 203,\n",
       " 230,\n",
       " 122,\n",
       " 112,\n",
       " 234,\n",
       " 224,\n",
       " 214,\n",
       " 204,\n",
       " 224,\n",
       " 123,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 195,\n",
       " 212,\n",
       " 204,\n",
       " 211,\n",
       " 203,\n",
       " 205,\n",
       " 200,\n",
       " 184,\n",
       " 213,\n",
       " 162,\n",
       " 138,\n",
       " 193,\n",
       " 207,\n",
       " 203,\n",
       " 231,\n",
       " 245,\n",
       " 208,\n",
       " 220,\n",
       " 211,\n",
       " 203,\n",
       " 219,\n",
       " 179,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 185,\n",
       " 191,\n",
       " 218,\n",
       " 233,\n",
       " 219,\n",
       " 201,\n",
       " 221,\n",
       " 213,\n",
       " 246,\n",
       " 114,\n",
       " 127,\n",
       " 80,\n",
       " 129,\n",
       " 232,\n",
       " 198,\n",
       " 218,\n",
       " 207,\n",
       " 236,\n",
       " 227,\n",
       " 220,\n",
       " 216,\n",
       " 172,\n",
       " 21,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 21,\n",
       " 4,\n",
       " 5,\n",
       " 64,\n",
       " 160,\n",
       " 224,\n",
       " 224,\n",
       " 144,\n",
       " 187,\n",
       " 197,\n",
       " 211,\n",
       " 207,\n",
       " 186,\n",
       " 192,\n",
       " 210,\n",
       " 212,\n",
       " 218,\n",
       " 225,\n",
       " 236,\n",
       " 177,\n",
       " 106,\n",
       " 56,\n",
       " 28,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 116,\n",
       " 252,\n",
       " 96,\n",
       " 120,\n",
       " 51,\n",
       " 73,\n",
       " 70,\n",
       " 123,\n",
       " 79,\n",
       " 76,\n",
       " 64,\n",
       " 162,\n",
       " 252,\n",
       " 118,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 115,\n",
       " 226,\n",
       " 145,\n",
       " 170,\n",
       " 155,\n",
       " 165,\n",
       " 161,\n",
       " 159,\n",
       " 125,\n",
       " 175,\n",
       " 140,\n",
       " 174,\n",
       " 236,\n",
       " 95,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 131,\n",
       " 225,\n",
       " 204,\n",
       " 217,\n",
       " 221,\n",
       " 220,\n",
       " 217,\n",
       " 224,\n",
       " 231,\n",
       " 226,\n",
       " 237,\n",
       " 203,\n",
       " 237,\n",
       " 102,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 135,\n",
       " 223,\n",
       " 201,\n",
       " 199,\n",
       " 194,\n",
       " 198,\n",
       " 195,\n",
       " 198,\n",
       " 192,\n",
       " 203,\n",
       " 199,\n",
       " 207,\n",
       " 231,\n",
       " 112,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 134,\n",
       " 223,\n",
       " 199,\n",
       " 206,\n",
       " 199,\n",
       " 201,\n",
       " 200,\n",
       " 203,\n",
       " 206,\n",
       " 207,\n",
       " 210,\n",
       " 206,\n",
       " 227,\n",
       " 119,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 139,\n",
       " 223,\n",
       " 198,\n",
       " 204,\n",
       " 200,\n",
       " 201,\n",
       " 200,\n",
       " 201,\n",
       " 204,\n",
       " 206,\n",
       " 208,\n",
       " 206,\n",
       " 229,\n",
       " 128,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 145,\n",
       " 223,\n",
       " 195,\n",
       " 205,\n",
       " 201,\n",
       " 201,\n",
       " 200,\n",
       " 204,\n",
       " 204,\n",
       " 206,\n",
       " 211,\n",
       " 205,\n",
       " 230,\n",
       " 139,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 157,\n",
       " 221,\n",
       " 194,\n",
       " 204,\n",
       " 204,\n",
       " 201,\n",
       " 201,\n",
       " 203,\n",
       " 205,\n",
       " 208,\n",
       " 211,\n",
       " 204,\n",
       " 230,\n",
       " 148,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 166,\n",
       " 220,\n",
       " 194,\n",
       " 203,\n",
       " 203,\n",
       " 205,\n",
       " 203,\n",
       " 203,\n",
       " 206,\n",
       " 207,\n",
       " 212,\n",
       " 204,\n",
       " 230,\n",
       " 157,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 171,\n",
       " 221,\n",
       " 195,\n",
       " 206,\n",
       " 200,\n",
       " 199,\n",
       " 203,\n",
       " 203,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 204,\n",
       " 226,\n",
       " 181,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 165,\n",
       " 224,\n",
       " 197,\n",
       " 201,\n",
       " 208,\n",
       " 199,\n",
       " 204,\n",
       " 205,\n",
       " 207,\n",
       " 210,\n",
       " 213,\n",
       " 207,\n",
       " 229,\n",
       " 187,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 128,\n",
       " 201,\n",
       " 203,\n",
       " 201,\n",
       " 207,\n",
       " 211,\n",
       " 203,\n",
       " 205,\n",
       " 206,\n",
       " 210,\n",
       " 213,\n",
       " 205,\n",
       " 225,\n",
       " 191,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 141,\n",
       " 201,\n",
       " 191,\n",
       " 188,\n",
       " 194,\n",
       " 187,\n",
       " 187,\n",
       " 191,\n",
       " 193,\n",
       " 195,\n",
       " 199,\n",
       " 199,\n",
       " 218,\n",
       " 161,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 212,\n",
       " 240,\n",
       " 213,\n",
       " 239,\n",
       " 233,\n",
       " 239,\n",
       " 231,\n",
       " 232,\n",
       " 236,\n",
       " 242,\n",
       " 245,\n",
       " 224,\n",
       " 245,\n",
       " 234,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 37,\n",
       " 69,\n",
       " 94,\n",
       " 123,\n",
       " 127,\n",
       " 138,\n",
       " 138,\n",
       " 142,\n",
       " 145,\n",
       " 135,\n",
       " 125,\n",
       " 103,\n",
       " 87,\n",
       " 56,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В azureml встроены много инструментов, которые призваны решить достаточно сложные инженерные проблемы. Например - простой и удобный запуск распределенного обучения. \n",
    "\n",
    "Сайчас попробуем решить ту же самую задачу, но используя фреймворк распределенного обучения Horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости дополнительно необходимо прописать библиотеку horovod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dist-deps.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile dist-deps.yaml\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - torch==1.6.0\n",
    "  - torchvision==0.7.0\n",
    "  - horovod==0.19.1\n",
    "  - future==0.17.1\n",
    "  - pillow\n",
    "  - pandas\n",
    "  - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "dist_pytorch_env = Environment.from_conda_specification(name = 'dist-pytorch-1.6-gpu', file_path = './dist-deps.yaml')\n",
    "\n",
    "dist_pytorch_env.docker.enabled = True\n",
    "dist_pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам скрипт необходимо незначительно обновить, добавив элементы распределенной синхронизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p dist-torch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dist-torch/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dist-torch/train.py\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import horovod.torch as hvd\n",
    "\n",
    "\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "hvd.init()  # Инициализируем хоровод\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "def load_data(data_dir, batch_size = 32):\n",
    "    train_csv = pd.read_csv(\"{}/fashion-mnist_train.csv\".format(data_dir))\n",
    "    test_csv = pd.read_csv(\"{}/fashion-mnist_test.csv\".format(data_dir))\n",
    "    \n",
    "    y_train = train_csv['label'].values\n",
    "    X_train = train_csv.drop(['label'],axis=1).values\n",
    "\n",
    "    y_test = test_csv['label'].values\n",
    "    X_test = test_csv.drop(['label'],axis=1).values\n",
    "\n",
    "    torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "    torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "    torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "    torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "    test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "    \n",
    "    # Данные дополнительно нужно опернуть в DistributedSampler, чтобы каждый воркер понимал, какую часть данных он обрабатывает\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train, \n",
    "        num_replicas=hvd.size(), # hvd.size возвращает общее количесто воркеров\n",
    "        rank=hvd.rank()  # hvd.rank возвращает номер текущего воркера\n",
    "    )\n",
    "    test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        test,\n",
    "        num_replicas=hvd.size(),\n",
    "        rank=hvd.rank()\n",
    "    )\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, \n",
    "        batch_size = batch_size, \n",
    "        sampler=train_sampler, \n",
    "        shuffle = False\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, \n",
    "        batch_size = batch_size, \n",
    "        sampler=test_sampler, \n",
    "        shuffle = False\n",
    "    )\n",
    "    \n",
    "    return train_loader, train_sampler, test_loader\n",
    "\n",
    "\n",
    "def fit(model, train_loader, train_sampler, epoch_number=20, batch_size=32, lr=0.001, momentum=0.9):\n",
    "    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n",
    "       \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "#     optimizer = optim.SGD(\n",
    "#         model.parameters(), \n",
    "#         lr=lr * hvd.size(),\n",
    "#         momentum=momentum\n",
    "#     )\n",
    "    \n",
    "    # Чтобы градиент считался распределенно, достаточно обернуть оптимизатор в DistributedOptimizer\n",
    "    optimizer = hvd.DistributedOptimizer(  \n",
    "        optimizer,\n",
    "        named_parameters=model.named_parameters()\n",
    "    )\n",
    "    \n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    # Далее сам процесс обучения идет как обычно\n",
    "    for epoch in range(epoch_number):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        correct = 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float().to(device)\n",
    "            var_y_batch = Variable(y_batch).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                loss = loss.data\n",
    "                accuracy = float(correct*100) / float(batch_size*(batch_idx+1))\n",
    "                run.log('Loss', float(loss))\n",
    "                run.log('Accuracy', float(accuracy))\n",
    "                \n",
    "                \n",
    "def evaluate(model, test_loader, batch_size=32):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float().to(device)\n",
    "        \n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels.to(device)).sum()\n",
    "\n",
    "    accuracy = float(correct) / (len(test_loader)*batch_size)\n",
    "    \n",
    "    accuracy_tensor = torch.tensor(accuracy)\n",
    "    # Чтобы корректно подсчитать качество на датасете, нужно сложить все данные со всех воркеров\n",
    "    # Для этого пользуемся функцией allreduce , которая засинхронизируем данные \n",
    "    avg_tensor = hvd.allreduce(accuracy_tensor, name='avg_accuracy')\n",
    "    result = avg_tensor.item()\n",
    "    \n",
    "    if hvd.rank() == 0:  # Чтобы итоговое качество было залогированно ровно 1 раз, отправим лог только с 0-го воркера\n",
    "        run.log('Test accuracy', result)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_path', type=str, help='Path to the training data')\n",
    "    parser.add_argument('--output_dir', type=str, help='output directory')\n",
    "    parser.add_argument('--num_epochs', type=int, default=20, help='number of epochs to train')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='number of examples in one batch')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, help='SGD momentum (default: 0.5)')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train_loader, train_sampler, test_loader = load_data(args.data_path, batch_size=args.batch_size)\n",
    "    \n",
    "    mlp = MLP()\n",
    "    mlp.to(device)\n",
    "    \n",
    "    fit(mlp, train_loader, train_sampler, epoch_number=args.num_epochs, batch_size=args.batch_size)\n",
    "    evaluate(mlp, test_loader)\n",
    "    \n",
    "    # Полученную модель будем сохранять только с одного воркера, а не со всех сразу\n",
    "    if hvd.rank() == 0:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "        torch.save(mlp.state_dict(), os.path.join(args.output_dir, 'model.json'))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "# Весь скрипт выглядит как обычно за исключением distributed_job_config\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='dist-torch',\n",
    "    script='train.py',\n",
    "    compute_target=compute_target,\n",
    "    environment=dist_pytorch_env,\n",
    "    arguments=[\n",
    "        '--num_epochs', 30, \n",
    "        '--output_dir', './outputs', \n",
    "        '--data_path', dataset.as_named_input('input').as_mount(),\n",
    "        '--batch_size', 32\n",
    "    ],\n",
    "    distributed_job_config=MpiConfiguration(node_count=3) # Указываем, что хотим 3 воркера для распределнного обучения\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-fashion_1615380733_d09ef41a\n",
      "Web View: https://ml.azure.com/experiments/pytorch-fashion/runs/pytorch-fashion_1615380733_d09ef41a?wsid=/subscriptions/7d1225ca-27cc-40b7-8036-c62a48072ba8/resourcegroups/lsml-resource-group/workspaces/ml-workspace-1\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-03-10T12:55:04Z Starting output-watcher...\n",
      "2021-03-10T12:55:04Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-03-10T12:55:31.603206] Entering job preparation.\n",
      "[2021-03-10T12:55:32.097889] Starting job preparation.\n",
      "[2021-03-10T12:55:32.097924] Extracting the control code.\n",
      "[2021-03-10T12:55:32.104506] Waiting for master node to finish fetching and extracting the control code. Will check again in 1 seconds.\n",
      "[2021-03-10T12:55:33.110064] Finished fetching and extracting the control code.\n",
      "[2021-03-10T12:55:33.110116] Not a master node. Skipping rest of the context managers.\n",
      "[2021-03-10T12:55:33.110134] Entering Data Context Managers in Sidecar\n",
      "[2021-03-10T12:55:33.110705] Running Sidecar prep cmd...\n",
      "[2021-03-10T12:55:33.164178] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/mounts/workspaceblobstore/azureml/pytorch-fashion_1615380733_d09ef41a\n",
      "[2021-03-10T12:55:33.164828] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.22.0 azureml-dataprep==2.10.1. Session id: 0a9c7311-d5b9-4927-ac0e-fd09ac981ff3. Run id: pytorch-fashion_1615380733_d09ef41a.\n",
      "Processing 'input'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'fashion-mnist-data')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"c5ccb8c4-acfd-4995-b18a-7796cf9e5753\",\n",
      "    \"name\": \"fashion-mnist-data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"Fashion mnist data\",\n",
      "    \"workspace\": \"Workspace.create(name='ml-workspace-1', subscription_id='7d1225ca-27cc-40b7-8036-c62a48072ba8', resource_group='lsml-resource-group')\"\n",
      "  }\n",
      "}\n",
      "Mounting input to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/wd/tmpgh5en1t6.\n",
      "Mounted input to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/wd/tmpgh5en1t6 as folder.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset input's target path to /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/wd/tmpgh5en1t6\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
      "[2021-03-10T12:55:41.590498] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-03-10T12:55:42.619424] Ran Sidecar prep cmd.\n",
      "[2021-03-10T12:55:42.619465] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log_0.txt\n",
      "==========================================\n",
      "\n",
      "bash: /azureml-envs/azureml_0a467d8476986fe17624e75182788a1d/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "[2021-03-10T12:57:42.310054] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--num_epochs', '30', '--output_dir', './outputs', '--data_path', 'DatasetConsumptionConfig:input', '--batch_size', '32'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 111\n",
      "[2021-03-10T12:57:44.152856] Entering Run History Context Manager.\n",
      "[2021-03-10T12:57:44.876892] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/mounts/workspaceblobstore/azureml/pytorch-fashion_1615380733_d09ef41a\n",
      "[2021-03-10T12:57:44.877024] Preparing to call script [train.py] with arguments:['--num_epochs', '30', '--output_dir', './outputs', '--data_path', '$input', '--batch_size', '32']\n",
      "[2021-03-10T12:57:44.877086] After variable expansion, calling script [train.py] with arguments:['--num_epochs', '30', '--output_dir', './outputs', '--data_path', '/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/wd/tmpniddk23j', '--batch_size', '32']\n",
      "\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: registering framework btl components\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: found loaded component tcp\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: component tcp register function successful\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: found loaded component sm\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: found loaded component vader\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: component vader register function successful\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: found loaded component self\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_register: component self register function successful\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: opening btl components\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: found loaded component tcp\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: component tcp open function successful\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: found loaded component vader\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: component vader open function successful\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: found loaded component self\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: components_open: component self open function successful\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] select: initializing btl component tcp\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: Attempting to bind to AF_INET port 1024\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: Successfully bound to AF_INET port 1024\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: my listening v4 socket is 0.0.0.0:1024\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: examining interface eth0\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: using ipv6 interface eth0\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] select: init of component tcp returned success\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] select: initializing btl component vader\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] select: init of component vader returned failure\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: close: component vader closed\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: base: close: unloading component vader\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] select: initializing btl component self\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] select: init of component self returned success\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: bml: Using self btl for send to [[8127,1],0] on node ebc95e5f1da142f291e5aae97b64d30e000001\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_param_files=/root/.openmpi/mca-params.conf:/usr/local/etc/openmpi-mca-params.conf (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_param_files=/root/.openmpi/mca-params.conf:/usr/local/etc/openmpi-mca-params.conf (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_override_param_file=/usr/local/etc/openmpi-mca-params-override.conf (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_suppress_override_warning=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_param_file_prefix= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_envar_file_prefix= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_param_file_path=/usr/local/share/openmpi/amca-param-sets:/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/mounts/workspaceblobstore/azureml/pytorch-fashion_1615380733_d09ef41a (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_param_file_path_force= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_signal=6,7,8,11 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_stacktrace_output=stderr (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_net_private_ipv4=10.0.0.0/8;172.16.0.0/12;192.168.0.0/16;169.254.0.0/16 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_set_max_sys_limits= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_built_with_cuda_support=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cuda_support=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_leave_pinned=auto (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_leave_pinned=auto (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_leave_pinned_pipeline=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_leave_pinned_pipeline=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_warn_on_fork=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_abort_delay=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_abort_print_stack=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_env_list= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_env_list_delimiter=; (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dss_buffer_type=non-described (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dss_buffer_initial_size=2048 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dss_buffer_threshold_size=4096 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_component_path=/usr/local/lib/openmpi:/root/.openmpi/components (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_component_path=/usr/local/lib/openmpi:/root/.openmpi/components (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_component_show_load_errors=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_component_show_load_errors=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_component_track_load_errors=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_component_disable_dlopen=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_component_disable_dlopen=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_base_verbose=stderr (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca_verbose=stderr (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dl= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dl_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dl_dlopen_filename_suffixes=.so,.dylib,.dll,.sl (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] if= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] if_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] if_base_do_not_resolve=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] if_base_retain_loopback=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_param_check=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_yield_when_idle=false (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_event_tick_rate=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_show_handle_leaks=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_no_free_handles=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_show_mpi_alloc_mem_leaks=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_show_mca_params=1 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_show_mca_params_file= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_preconnect_all=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_have_sparse_group_storage=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_use_sparse_group_storage=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_cuda_support=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_built_with_cuda_support=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_add_procs_cutoff=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_dynamics_enabled=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] async_mpi_init=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] async_mpi_finalize=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_abort_delay=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpi_abort_print_stack=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ompi_timing=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hook= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hook_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rte= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rte_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_mem_alloc_policy=none (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_mem_bind_failure_action=warn (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_binding_policy=none (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_bind_to_core=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_bind_to_socket=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_report_bindings=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_cpu_list= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_slot_list= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_cpu_set= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_use_hwthreads_as_cpus=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] hwloc_base_topo_file= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] memcpy= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] memcpy_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] memchecker= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] memchecker_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] backtrace= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] backtrace_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] timer= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] timer_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] timer_require_monotonic=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] event= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] event_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] event_libevent2022_event_include=poll (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_event_include=poll (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] shmem= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] shmem_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] shmem_mmap_priority=50 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] shmem_mmap_enable_nfs_warning=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] shmem_mmap_relocate_backing_file=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] shmem_mmap_backing_file_base_dir=/dev/shm (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] reachable= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] reachable_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_verbose=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ft_cr_enabled=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_enable_timer=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_enable_timer_barrier=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_timer_target_rank=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_is_tool=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_signal=10 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_debug_sigpipe=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] opal_cr_tmp_dir=/tmp (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_base_help_aggregate=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_tmpdir_base=/tmp (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_local_tmpdir_base= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_remote_tmpdir_base= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_top_session_dir=/tmp/ompi.ebc95e5f1da142f291e5aae97b64d30e000001.0 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_jobfam_session_dir=/tmp/ompi.ebc95e5f1da142f291e5aae97b64d30e000001.0/pid.89 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_no_session_dirs= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_create_session_dirs=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_execute_quiet=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_report_silent_errors=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debug=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debug_verbose=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debug_daemons_file=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debug_daemons=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_progress_thread_debug=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_leave_session_attached=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_output_debugger_proctable=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debugger_test_daemon= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debugger_test_attach=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_debugger_check_rate=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_do_not_launch=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_daemon_spin=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_daemon_fail=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_daemon_fail_delay=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_startup_timeout=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_base_user_debugger=totalview @mpirun@ -a @mpirun_args@ : ddt -n @np@ -start @executable@ @executable_argv@ @single_app@ : fxp @mpirun@ -a @mpirun_args@ (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_default_hostfile=/usr/local/etc/openmpi-default-hostfile (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_default_dash_host= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_node_regex= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_keep_fqdn_hostnames=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_retain_aliases=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_hostname_cutoff=1000 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_hostname_alias_index=1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_xml_output=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_tag_output=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_xml_file= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_timestamp_output=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_show_resolved_nodenames=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_launch_agent=orted (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_fork_agent= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_allocation_required=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_map_stddiag_to_stderr=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_map_stddiag_to_stdout=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_xterm= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_report_launch_progress=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_report_events= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_enable_recovery=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_max_restarts=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_abort_on_non_zero_status=true (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_allowed_exit_without_sync=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_report_child_jobs_separately=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_stat_history_size=1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_no_vm=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_max_vm_size=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_set_default_slots=cores (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_display_alloc=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ras_base_display_alloc=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_display_devel_alloc=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ras_base_display_devel_alloc=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_soft_locations=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_daemon_cores= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_coll_transports=fabric,ethernet (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_mgmt_transports=oob (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_timeout_for_stack_trace=30 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_fwd_mpirun_port=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix_server_uri= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_strip_prefix= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] schizo= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] schizo_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] schizo_base_personalities= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ess=pmi (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ess_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ess_base_stream_buffering=default (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_ess_jobid=532611073 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_ess_vpid=0 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_ess_num_procs=3 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ess_base_forward_signals= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] ess_hnp_forward_signals= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix=^s1,s2,cray,isolated (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix_base_async_modex=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix_base_collect_data=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix_base_exchange_timeout=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pmix_pmix2x_silence_warning=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] state= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] state_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] state_base_check_fds=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] errmgr= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] errmgr_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] errmgr_default_app_priority=1000 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] routed= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] routed_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] routed_radix=64 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_base_num_progress_threads=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_peer_limit=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_peer_retries=2 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_sndbuf=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_rcvbuf=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_if_include=eth0 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_if_exclude= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_static_ipv4_ports= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_dynamic_ipv4_ports= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_disable_ipv4_family=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_keepalive_time=300 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_keepalive_intvl=20 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_keepalive_probes=9 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_retry_delay=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] oob_tcp_max_recon_attempts=10 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rml= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rml_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rml_base_max_retries=3 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] grpcomm= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] grpcomm_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] grpcomm_direct_priority=85 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] orte_cr_verbose=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dfs= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] dfs_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] op= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] op_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] allocator= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] allocator_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] allocator_bucket_num_buckets=30 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rcache= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rcache_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rcache_base_vma_tree_items_min=2048 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rcache_base_vma_tree_items_max=16384 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rcache_base_vma_tree_items_inc=2048 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] rcache_grdma_print_stats=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpool= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpool_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpool_hugepage_priority=50 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mpool_hugepage_page_size=2097152 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] bml= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] bml_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] bml_r2_show_unreach_errors=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_base_verbose=30 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_base_include= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_base_exclude= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_base_warn_component_unused=1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_links=1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_if_include=eth0 (environment)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_if_exclude=127.0.0.1/8,sppp (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_free_list_num=8 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_free_list_max=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_free_list_inc=32 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_sndbuf=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_rcvbuf=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_endpoint_cache=30720 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_use_nagle=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_port_min_v4=1024 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_port_range_v4=64511 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_progress_thread=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_warn_all_unfound_interfaces=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_exclusivity=100 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_flags=send,put,inplace,need-ack,need-csum,hetero-rdma (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_atomic_flags= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_rndv_eager_limit=65536 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_eager_limit=65536 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_put_limit=18446744073709551615 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_put_alignment=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_max_send_size=131072 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_rdma_pipeline_send_length=131072 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_rdma_pipeline_frag_size=2147482624 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_min_rdma_pipeline_size=196608 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_latency=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_bandwidth=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_disable_family=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_free_list_num=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_free_list_max=64 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_free_list_inc=8 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_exclusivity=65536 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_flags=send,put,get,inplace (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_atomic_flags= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_rndv_eager_limit=131072 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_eager_limit=1024 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_get_limit=18446744073709551615 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_get_alignment=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_put_limit=18446744073709551615 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_put_alignment=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_max_send_size=16384 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_rdma_pipeline_send_length=2147483647 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_rdma_pipeline_frag_size=2147483647 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_min_rdma_pipeline_size=2147484671 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_latency=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_self_bandwidth=100 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_bandwidth_eth0=40000 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_latency_eth0=100 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_bandwidth_eth0:0=40000 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl_tcp_latency_eth0:0=100 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_base_bsend_allocator=basic (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_verbose=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_free_list_num=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_free_list_max=-1 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_free_list_inc=64 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_priority=20 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_send_pipeline_depth=3 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_recv_pipeline_depth=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_max_rdma_per_request=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_max_send_per_range=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_unexpected_limit=128 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_use_all_rdma=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] pml_ob1_allocator=bucket (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_self_priority=75 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_basic_priority=10 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_basic_crossover=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sync_priority=50 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sync_barrier_before=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sync_barrier_after=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_libnbc_priority=10 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_libnbc_ibcast_skip_dt_decision=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_spacc_priority=5 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_spacc_verbose=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_priority=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_control_size=4096 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_fragment_size=8192 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_comm_in_use_flags=2 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_comm_num_segments=8 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_tree_degree=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_info_num_procs=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_sm_shared_mem_used_data=548864 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_priority=30 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_init_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_init_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_small_msg=200 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_intermediate_msg=3000 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_use_dynamic_rules=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_dynamic_rules_filename= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allreduce_algorithm_count=6 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allreduce_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allreduce_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allreduce_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allreduce_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_algorithm_count=6 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoall_algorithm_max_requests=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgather_algorithm_count=7 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgather_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgather_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgather_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgather_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgatherv_algorithm_count=6 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgatherv_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgatherv_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgatherv_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_allgatherv_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoallv_algorithm_count=3 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_alltoallv_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_barrier_algorithm_count=7 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_barrier_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_bcast_algorithm_count=7 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_bcast_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_bcast_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_bcast_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_bcast_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_algorithm_count=7 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_algorithm_max_requests=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_scatter_algorithm_count=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_scatter_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_scatter_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_scatter_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_reduce_scatter_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_gather_algorithm_count=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_gather_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_gather_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_gather_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_gather_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_scatter_algorithm_count=3 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_scatter_algorithm=ignore (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_scatter_algorithm_segmentsize=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_scatter_algorithm_tree_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_tuned_scatter_algorithm_chain_fanout=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_inter_priority=40 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] coll_inter_verbose=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc= (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_base_verbose=error (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_pt2pt_no_locks=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_pt2pt_buffer_size=8192 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_pt2pt_receive_count=4 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_sm_backing_directory=/dev/shm (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_no_locks=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_acc_single_intrinsic=false (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_acc_use_amo=true (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_buffer_size=32768 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_max_attach=32 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_aggregation_limit=0 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_priority=101 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_locking_mode=two_level (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_btls=openib,ugni,uct,ucp (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_mtls=psm2 (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] osc_rdma_backing_directory=/dev/shm (default)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: path from 10.0.0.5 to 10.0.0.6: IPV4 PRIVATE SAME NETWORK\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: now connected to 10.0.0.6, process [[8127,1],2]\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: path from 10.0.0.5 to 10.0.0.4: IPV4 PRIVATE SAME NETWORK\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] btl:tcp: now connected to 10.0.0.4, process [[8127,1],1]\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: bml: Using tcp btl for send to [[8127,1],1] on node (null)\n",
      "[ebc95e5f1da142f291e5aae97b64d30e000001:00111] mca: bml: Using tcp btl for send to [[8127,1],2] on node (null)\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Bootstrap : Using eth0:10.0.0.5<0>\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so), using internal implementation\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.0.5<0>\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Using network Socket\n",
      "NCCL version 2.8.3+cuda10.1\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 00/02 :    0   1   2\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 01/02 :    0   1   2\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Trees [0] 2/-1/-1->0->-1 [1] 2/-1/-1->0->1\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Setting affinity for GPU 0 to 3f\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 00 : 2[100000] -> 0[100000] [receive] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 01 : 2[100000] -> 0[100000] [receive] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 00 : 0[100000] -> 1[100000] [send] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 01 : 0[100000] -> 1[100000] [send] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Connected all rings\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 01 : 1[100000] -> 0[100000] [receive] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 00 : 0[100000] -> 2[100000] [send] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Channel 01 : 0[100000] -> 2[100000] [send] via NET/Socket/0\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Connected all trees\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 8/8/64\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO comm 0x7fceb82facb0 rank 0 nranks 3 cudaDev 0 busId 100000 - Init COMPLETE\n",
      "ebc95e5f1da142f291e5aae97b64d30e000001:111:126 [0] NCCL INFO Launch mode Parallel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-03-10T13:02:05.660963] Entering job release\n",
      "[2021-03-10T13:02:06.641752] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-03-10T13:02:06.641791] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-03-10T13:02:06.641806] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-03-10T13:02:06.642174] Running Sidecar release cmd...\n",
      "[2021-03-10T13:02:06.649575] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/mounts/workspaceblobstore/azureml/pytorch-fashion_1615380733_d09ef41a\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/wd/tmpgh5en1t6.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/ml-workspace-1/azureml/pytorch-fashion_1615380733_d09ef41a/wd/tmpgh5en1t6.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-03-10T13:02:06.835144] Removing absolute paths from host...\n",
      "[2021-03-10T13:02:07.137404] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-03-10T13:02:07.922639] Ran Sidecar release cmd.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-fashion_1615380733_d09ef41a\n",
      "Web View: https://ml.azure.com/experiments/pytorch-fashion/runs/pytorch-fashion_1615380733_d09ef41a?wsid=/subscriptions/7d1225ca-27cc-40b7-8036-c62a48072ba8/resourcegroups/lsml-resource-group/workspaces/ml-workspace-1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'pytorch-fashion_1615380733_d09ef41a',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-03-10T12:55:01.895262Z',\n",
       " 'endTimeUtc': '2021-03-10T13:02:28.354511Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'c930178b-fdd5-4b07-888c-73c0531d72e6',\n",
       "  'azureml.git.repository_uri': 'git@github.com:ADKosm/lsml-2021-internal.git',\n",
       "  'mlflow.source.git.repoURL': 'git@github.com:ADKosm/lsml-2021-internal.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '4930b05f6a80ba0707e4a0c958d4c990c07254ac',\n",
       "  'mlflow.source.git.commit': '4930b05f6a80ba0707e4a0c958d4c990c07254ac',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'c5ccb8c4-acfd-4995-b18a-7796cf9e5753'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--num_epochs',\n",
       "   '30',\n",
       "   '--output_dir',\n",
       "   './outputs',\n",
       "   '--data_path',\n",
       "   'DatasetConsumptionConfig:input',\n",
       "   '--batch_size',\n",
       "   '32'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'Mpi',\n",
       "  'target': 'gpucluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input': {'dataLocation': {'dataset': {'id': 'c5ccb8c4-acfd-4995-b18a-7796cf9e5753',\n",
       "      'name': 'fashion-mnist-data',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 3,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'dist-pytorch-1.6-gpu',\n",
       "   'version': 'Autosave_2021-03-10T07:56:52Z_98b27dd1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'torch==1.6.0',\n",
       "        'torchvision==0.7.0',\n",
       "        'horovod==0.19.1',\n",
       "        'future==0.17.1',\n",
       "        'pillow',\n",
       "        'pandas',\n",
       "        'numpy']}],\n",
       "     'name': 'azureml_0a467d8476986fe17624e75182788a1d'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/55_azureml-execution-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt?sv=2019-02-02&sr=b&sig=my8d4sPnX8NRfvprdJ3EzuqRGpw4DcJCnKEEhna5go0%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/55_azureml-execution-tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p.txt?sv=2019-02-02&sr=b&sig=i6JRPLhUjT%2Bum4PqOn6sU9RZQBHpTB56%2BQtrseDivAw%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/55_azureml-execution-tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p.txt?sv=2019-02-02&sr=b&sig=NGHOE4rXT%2FvWzCEYI1QwCEQw%2BHoCM7UfA0n673vmrsY%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/65_job_prep-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt?sv=2019-02-02&sr=b&sig=QvV8FquWmeU3Jg2rtUzOyyQwMwXYa9GxJGSFa81tZA0%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/65_job_prep-tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p.txt?sv=2019-02-02&sr=b&sig=nnf3e63C79S85YOjnfeTcikaJpoQnuAiR6CGVHBfsmo%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/65_job_prep-tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p.txt?sv=2019-02-02&sr=b&sig=Zc5iZOhb8mXD19et4tBXAyeEuUTX%2FOJXbkdCcu7Iv28%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_0.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=dXySzl4gj3u7lYhO23%2F%2FCx4XZ07UIlk4WUkzeTRILuE%3D&st=2021-03-10T12%3A52%3A23Z&se=2021-03-10T21%3A02%3A23Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_1.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=sFqFRb9ctDLHI%2Fun38lvEsebQe03E6dVTUUIK2giYhA%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_2.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/70_driver_log_2.txt?sv=2019-02-02&sr=b&sig=yVh5JRxQeZfIW0%2B3JWuhtrT2PQ5mo0ZCGGLqdnl1m64%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/70_mpi_log.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/70_mpi_log.txt?sv=2019-02-02&sr=b&sig=DHeGbpLZ0XN7u8N%2BCxRc4BoYhc178XdNjOXG6RNTt68%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/75_job_post-tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p.txt?sv=2019-02-02&sr=b&sig=BcfsQDWVp9IUMUdSm5nVVyV04r8q2cIsfbMr3wroejM%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/75_job_post-tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p.txt?sv=2019-02-02&sr=b&sig=dRryvkopYVCw%2BmjYEPAFBRwe4lzO2DszsjhxMYuzPn0%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p.txt': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/75_job_post-tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p.txt?sv=2019-02-02&sr=b&sig=lE3YPAWw1h2kb4kCFklsdOdcU3%2BlaKg1pF%2Bjuqv3knM%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=gohh6sutLIfI5SjrTOo9zilhgEr7a7sNV2sPA2Kohws%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=%2Fb3ePS%2Bv714py9WViqhY84e%2BhzltMeVmpmikEHbnuXw%3D&st=2021-03-10T12%3A52%3A24Z&se=2021-03-10T21%3A02%3A24Z&sp=r',\n",
       "  'logs/azureml/0_111_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/0_111_azureml.log?sv=2019-02-02&sr=b&sig=NXyc7039m8Yaqwg2bhjxXdpxpdc%2F9AD1crU7UVWA9Dc%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/1_92_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/1_92_azureml.log?sv=2019-02-02&sr=b&sig=KS0L5T5j7vH34Cbvt499nRFoB1kAjiFSBwmLQoYb4PY%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/2_92_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/2_92_azureml.log?sv=2019-02-02&sr=b&sig=oqZJCZC%2BCFqzdc%2Fr3p%2FbNjwiKAJaSupcz4%2Fw8zADpgc%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=SGZIO5sHr5x1H9S4hjfz%2BkOKX0W7a%2F64%2BLZh48bFLyc%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=op1t48tygUSg22jj7xaun4gl2ieGz93HgY2GpXeaTEg%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=WeZJ%2BeQ0OKpCUlLZklIdhxL2bfAuOL66X%2BjVOsz3RHk%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=O7M0Q2C3HkDhWPzVJGQCQYjWnXDLAV29vOzdSQSuxFU%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p/all.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p/all.log?sv=2019-02-02&sr=b&sig=kowbTao7dy0BfJPxlVeW8EtzV0HyuFz%2BJYUzJZepRjU%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p/task.enter_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=qA0gLfGkPwu7cPnIXOG3RtXjoGfmIsm0EJIiTBCVqKE%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p/task.exit_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_15087d86362e38a40e5a4d79590601ebc2754e1beac8d657e0bd98983025aef5_p/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=308N%2BHrtDCD%2Fk0pVxOpTL%2BKDHgN20nZBb6Ruwy2zNyg%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p/all.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p/all.log?sv=2019-02-02&sr=b&sig=KKYas63MdgxBxSJvhQEVeyvhfKh6fSVqYzIfzx30pbY%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p/task.enter_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=guvQDvmw%2BemtlNFoMWoxgjRB9pUH%2BBhieSHWuTy9QHM%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p/task.exit_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_4f9b052822ada53bd23e8a8bcefe5418dacac1becf9c9bbd1f6640a12b8d652a_p/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=rlGuY4TWkhhXf3xck7SeMB%2FRr8WquwGwjzXSV6kdgXk%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p/all.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p/all.log?sv=2019-02-02&sr=b&sig=bCqYRUsLP4BbhkGUEhFFI1btkqd2MNC%2Bheh6fhlKuJk%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p/task.enter_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=g7j8osUxU%2BZNCX3zQjXuBX0UDLnOLomikMYTrpfJviQ%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p/task.exit_contexts.log': 'https://mlworkspstoragec2062ce86.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-fashion_1615380733_d09ef41a/logs/azureml/sidecar/tvmps_7cc4c546fc96368991b26e86d71cfd61aa2a067aa3cb6131bc4fbab5ae1d9733_p/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=YR%2Bp3kOmNlez57uelHD5uQ8XtCUcNVy%2FAp60PjE7cV0%3D&st=2021-03-10T12%3A52%3A22Z&se=2021-03-10T21%3A02%3A22Z&sp=r'},\n",
       " 'submittedBy': 'Алексей Космачев'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(src)\n",
    "run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в нашем распоряжении целый кластер, мы можем эффективно подбирать гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p hyperdrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyperdrive/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperdrive/train.py\n",
    "\n",
    "from __future__ import print_function, division\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "def load_data(data_dir, batch_size = 32):\n",
    "    train_csv = pd.read_csv(\"{}/fashion-mnist_train.csv\".format(data_dir))\n",
    "    test_csv = pd.read_csv(\"{}/fashion-mnist_test.csv\".format(data_dir))\n",
    "    \n",
    "    y_train = train_csv['label'].values\n",
    "    X_train = train_csv.drop(['label'],axis=1).values\n",
    "\n",
    "    y_test = test_csv['label'].values\n",
    "    X_test = test_csv.drop(['label'],axis=1).values\n",
    "\n",
    "    torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "    torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "    torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "    torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "    test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def fit(model, train_loader, epoch_number=5, batch_size=32, learning_rate=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    run.log('learning_rate', np.float(learning_rate))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoch_number):\n",
    "        correct = 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float().to(device)\n",
    "            var_y_batch = Variable(y_batch).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                loss = loss.data\n",
    "                accuracy = float(correct*100) / float(batch_size*(batch_idx+1))\n",
    "                run.log('loss', float(loss))\n",
    "                run.log('accuracy', float(accuracy))\n",
    "                \n",
    "                \n",
    "def evaluate(model, test_loader, batch_size=32):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float().to(device)\n",
    "        \n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels.to(device)).sum()\n",
    "    \n",
    "    accuracy = float(correct) / (len(test_loader)*batch_size)\n",
    "    # Сохраняем в лог какую-то метрику, которую будет оптимизировать подбором гиперпараметров\n",
    "    run.log('test_accuracy', accuracy)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_path', type=str, help='Path to the training data')\n",
    "    parser.add_argument('--output_dir', type=str, help='output directory')\n",
    "    parser.add_argument('--num_epochs', type=int, default=20, help='number of epochs to train')\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help='number of examples in one batch')\n",
    "    # Этот параметр будет перебирать\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.3, help='learning rate')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train_loader, test_loader = load_data(args.data_path, batch_size=args.batch_size)\n",
    "    \n",
    "    mlp = MLP()\n",
    "    mlp.to(device)\n",
    "    \n",
    "    fit(mlp, train_loader, epoch_number=args.num_epochs, batch_size=args.batch_size, learning_rate=args.learning_rate)\n",
    "    evaluate(mlp, test_loader)\n",
    "    \n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    torch.save(mlp.state_dict(), os.path.join(args.output_dir, 'model.json'))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyper-deps.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyper-deps.yaml\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - torch==1.6.0\n",
    "  - torchvision==0.7.0\n",
    "  - future==0.17.1\n",
    "  - pillow\n",
    "  - pandas\n",
    "  - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-gpu', file_path = './hyper-deps.yaml')\n",
    "\n",
    "pytorch_env.docker.enabled = True\n",
    "pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "# Создаем обычный конфиг для запуска задачи\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='hyperdrive',\n",
    "    script='train.py',\n",
    "    arguments=[\n",
    "        '--num_epochs', 30, \n",
    "        '--output_dir', './outputs', \n",
    "        '--data_path', dataset.as_named_input('input').as_mount(),\n",
    "        '--batch_size', 32\n",
    "    ],\n",
    "    compute_target=compute_target,\n",
    "    environment=pytorch_env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, HyperDriveConfig, uniform, PrimaryMetricGoal\n",
    "\n",
    "# Указываем, как именно будет подбирать гиперпараметры. \n",
    "# Указанные параметры будут добавлены к аргументам командной строки\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        'learning_rate': uniform(0.0005, 0.005),\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n",
    "\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    run_config=src,\n",
    "    hyperparameter_sampling=param_sampling, \n",
    "    policy=early_termination_policy,\n",
    "    primary_metric_name='test_accuracy',  # Какую метрику оптимизируем\n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,  # Как именно оптимизируем - max или min\n",
    "    max_total_runs=8,  # Сколько вообще делать экспериментов с параметрами\n",
    "    max_concurrent_runs=4  # Сколько задач можно запустить одноременно на кластере\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем самую лучшую модель по метрике\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.delete(delete_dependent_resources=True, no_wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
